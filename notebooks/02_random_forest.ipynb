{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.inspection import permutation_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from .csv file\n",
    "data = pd.read_csv('../data/heart_failure_records.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no information on hyperparameter tuning of Random Forest classifier. The authors are aware of the concept, since they apply tuning to SVM and Multi-layer Perceptron, but mention Random Forest with other methods that do not require tuning, such as Logistic Regression. This implies that authors used default hyperparameters specified in the `randomForest` R package.\n",
    "\n",
    "Based on this we can deduce that the hyperparameters are:\n",
    "- number of trees: 500\n",
    "- fraction of features sampled at each split: $\\sqrt n$, where $n$ is the number of features\n",
    "- fraction of observation sampled at each split: 1 \n",
    "- maximum leaf nodes in each tree: unlimited\n",
    "- minimum size of terminal nodes / minimum samples in a leaf: 1\n",
    "\n",
    "It should be noted that while the default hyperparameter for `scikit-learn` implementation of Random Forest classifier are mostly the same, the most important hyperparameter, the number of trees grown, is different: 100. This can be only deduced from the code made available by the researchers and is not stated in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc_auc_scores = []\n",
    "pr_auc_scores = []\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "tp_scores = []\n",
    "tn_scores = []\n",
    "mcc_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Instantiate series for accumulating feature importance rankings\n",
    "rf_mdi_importance = pd.Series(0, index=data.drop(columns=['DEATH_EVENT', 'time']).columns, name='mean_impurity_decrease_rank')\n",
    "rf_perm_importance = pd.Series(0, index=data.drop(columns=['DEATH_EVENT', 'time']).columns, name='mean_accuracy_decrease_rank')\n",
    "\n",
    "# We do not need to use the same seed as researchers, since random number generator implementations\n",
    "# are different in R and NumPy, so the partitions will always be different.\n",
    "# We set this only once, since we want different partitions in each run.\n",
    "np.random.seed(12345)\n",
    "\n",
    "# Both performance assessment and feature importance are averaged over 100 runs\n",
    "for i in range(100):\n",
    "    # Partition data into 80/20 training/test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['DEATH_EVENT', 'time']), data['DEATH_EVENT'], test_size=0.2)\n",
    "\n",
    "    # Instantiate, train, predict\n",
    "    rf = RandomForestClassifier(n_estimators=500)\n",
    "    rf.fit(X_train, y_train)\n",
    "    y_pred = rf.predict(X_test)\n",
    "\n",
    "    # Calculate performance assessment metrics\n",
    "    roc_auc_scores.append(metrics.roc_auc_score(y_test, y_pred))\n",
    "    y, x, _ = metrics.precision_recall_curve(y_test, y_pred)\n",
    "    pr_auc_scores.append(metrics.auc(x, y))\n",
    "    accuracy_scores.append(metrics.accuracy_score(y_test, y_pred))\n",
    "    f1_scores.append(metrics.f1_score(y_test, y_pred))\n",
    "    tp_scores.append(metrics.recall_score(y_test, y_pred))\n",
    "    tn_scores.append(metrics.recall_score(y_test, y_pred, pos_label=0))\n",
    "    mcc_scores.append(metrics.matthews_corrcoef(y_test, y_pred))\n",
    "\n",
    "    # Partition data into 70/30 training/test - researchers used different split than in performance assessment\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data.drop(columns=['DEATH_EVENT', 'time']), data['DEATH_EVENT'], test_size=0.3)\n",
    "\n",
    "    # Instantiate, train, predict using new partitions\n",
    "    rf = RandomForestClassifier(n_estimators=500)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    # Calculate and rank feature importances\n",
    "    rf_importance_1 = pd.Series(\n",
    "        rf.feature_importances_,\n",
    "        index=rf.feature_names_in_,\n",
    "        name='mean_impurity_decrease'\n",
    "    ).sort_values().rank(ascending=False)\n",
    "\n",
    "    # Calculate permutation importance on training data, as in the paper\n",
    "    result = permutation_importance(rf, X_train, y_train, n_repeats=5)\n",
    "    rf_importance_2 = pd.Series(\n",
    "        result.importances_mean,\n",
    "        index=rf.feature_names_in_,\n",
    "        name='mean_accuracy_decrease'\n",
    "    ).sort_values().rank(ascending=False)\n",
    "\n",
    "    # Accumulate rankings\n",
    "    rf_mdi_importance += rf_importance_1\n",
    "    rf_perm_importance += rf_importance_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Researchers calculated all feature importance rankings on training data. We consider this a methodological mistake - with deep trees grown on such a small number of observations (`n=299`), the results are of little value, since they are likely driven by noise in the data, rather than underlying relationships. The goal of the paper is to use feature importance for selecting the top features, to be then used to make predictions on the test set with a more parsimonious model. With that goal in mind, it would be preferable in our view to split the data into training, validation and test set and calculate relevant importances on the validation set (e.g. permutation importance). Also, the authors state that the training set is 70% of all observations, which is incosistent to 80% stated in model performance assessment. \n",
    "\n",
    "Due to differences in random number generation, it is impossible to fully reproduce the figures in another language, however the researchers repeated importance calculation on 100 different splits, which should minimize the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "serum_creatinine             1.0\n",
       "ejection_fraction            2.0\n",
       "age                          3.0\n",
       "serum_sodium                 4.0\n",
       "creatinine_phosphokinase     5.0\n",
       "platelets                    6.0\n",
       "sex                          7.0\n",
       "anaemia                      8.0\n",
       "diabetes                     9.0\n",
       "high_blood_pressure         10.0\n",
       "smoking                     11.0\n",
       "Name: rank_agg, dtype: float64"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances = pd.DataFrame(rf_mdi_importance).join(rf_perm_importance)\n",
    "\n",
    "# Calculate aggregate ranking using Borda's method - i.e. sum individual ranks from multiple runs and rank the sums in ascending order\n",
    "importances['rank_sum'] = importances['mean_accuracy_decrease_rank'] + importances['mean_impurity_decrease_rank']\n",
    "importances['rank_agg'] = importances['rank_sum'].rank()\n",
    "\n",
    "importances['rank_agg'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_impurity_decrease</th>\n",
       "      <th>mean_accuracy_decrease</th>\n",
       "      <th>rank_mdi_dec</th>\n",
       "      <th>rank_acc_dec</th>\n",
       "      <th>rank_sum</th>\n",
       "      <th>rank_borda</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>serum_creatinine</th>\n",
       "      <td>0.207998</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ejection_fraction</th>\n",
       "      <td>0.193029</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>anaemia</th>\n",
       "      <td>0.023365</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serum_sodium</th>\n",
       "      <td>0.117418</td>\n",
       "      <td>-0.010000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.155751</td>\n",
       "      <td>-0.023333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <td>0.114392</td>\n",
       "      <td>-0.021667</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>13.5</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking</th>\n",
       "      <td>0.017881</td>\n",
       "      <td>-0.001667</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <td>0.022921</td>\n",
       "      <td>-0.016667</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>0.017420</td>\n",
       "      <td>-0.003333</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>platelets</th>\n",
       "      <td>0.110927</td>\n",
       "      <td>-0.031667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diabetes</th>\n",
       "      <td>0.018898</td>\n",
       "      <td>-0.021667</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.5</td>\n",
       "      <td>17.5</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          mean_impurity_decrease  mean_accuracy_decrease   \n",
       "serum_creatinine                        0.207998                0.046667  \\\n",
       "ejection_fraction                       0.193029                0.035000   \n",
       "anaemia                                 0.023365                0.000000   \n",
       "serum_sodium                            0.117418               -0.010000   \n",
       "age                                     0.155751               -0.023333   \n",
       "creatinine_phosphokinase                0.114392               -0.021667   \n",
       "smoking                                 0.017881               -0.001667   \n",
       "high_blood_pressure                     0.022921               -0.016667   \n",
       "sex                                     0.017420               -0.003333   \n",
       "platelets                               0.110927               -0.031667   \n",
       "diabetes                                0.018898               -0.021667   \n",
       "\n",
       "                          rank_mdi_dec  rank_acc_dec  rank_sum  rank_borda  \n",
       "serum_creatinine                   1.0           1.0       2.0         1.0  \n",
       "ejection_fraction                  2.0           2.0       4.0         2.0  \n",
       "anaemia                            7.0           3.0      10.0         3.0  \n",
       "serum_sodium                       4.0           6.0      10.0         3.0  \n",
       "age                                3.0          10.0      13.0         5.0  \n",
       "creatinine_phosphokinase           5.0           8.5      13.5         6.0  \n",
       "smoking                           10.0           4.0      14.0         7.0  \n",
       "high_blood_pressure                8.0           7.0      15.0         8.0  \n",
       "sex                               11.0           5.0      16.0         9.0  \n",
       "platelets                          6.0          11.0      17.0        10.0  \n",
       "diabetes                           9.0           8.5      17.5        11.0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "importances['rank_mdi_dec'] = importances['mean_impurity_decrease'].rank(ascending=False)\n",
    "importances['rank_acc_dec'] = importances['mean_accuracy_decrease'].rank(ascending=False)\n",
    "importances['rank_sum'] = importances['rank_mdi_dec'] + importances['rank_acc_dec']\n",
    "importances['rank_borda'] = importances['rank_sum'].rank(method='min')\n",
    "importances.sort_values('rank_borda')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
